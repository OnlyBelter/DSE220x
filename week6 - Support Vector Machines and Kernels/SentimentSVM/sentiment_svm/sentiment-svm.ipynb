{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with support vector machines\n",
    "\n",
    "In this notebook, we will revisit a learning task that we encountered earlier in the course: predicting the *sentiment* (positive or negative) of a single sentence taken from a review of a movie, restaurant, or product. The data set consists of 3000 labeled sentences, which we divide into a training set of size 2500 and a test set of size 500. Previously we found a logistic regression classifier. Today we will use a support vector machine.\n",
    "\n",
    "Before starting on this notebook, make sure the folder `sentiment_labelled_sentences` (containing the data file `full_set.txt`) is in the same directory. Recall that the data can be downloaded from https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing the data\n",
    " \n",
    "Here we follow exactly the same steps as we did earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (2500, 4500)\n",
      "test data:  (500, 4500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Read in the data set.\n",
    "with open(\"sentiment_labelled_sentences/full_set.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "## Remove leading and trailing white space\n",
    "content = [x.strip() for x in content]\n",
    "\n",
    "## Separate the sentences from the labels\n",
    "sentences = [x.split(\"\\t\")[0] for x in content]\n",
    "labels = [x.split(\"\\t\")[1] for x in content]\n",
    "\n",
    "## Transform the labels from '0 v.s. 1' to '-1 v.s. 1'\n",
    "y = np.array(labels, dtype='int8')\n",
    "y = 2*y - 1\n",
    "\n",
    "# ## Read in the data set.\n",
    "# with open(\"sentiment_labelled_sentences/full_set.txt\") as f:\n",
    "#     content = f.readlines()\n",
    "    \n",
    "# ## Remove leading and trailing white space\n",
    "# content = [x.strip() for x in content]\n",
    "\n",
    "# ## Separate the sentences from the labels\n",
    "# sentences = [x.split(\"\\t\")[0] for x in content]\n",
    "# labels = [x.split(\"\\t\")[1] for x in content]\n",
    "\n",
    "# ## Transform the labels from '0 v.s. 1' to '-1 v.s. 1'\n",
    "# y = np.array(labels, dtype='int8')\n",
    "# y = 2*y - 1\n",
    "\n",
    "## full_remove takes a string x and a list of characters removal_list \n",
    "## returns x with all the characters in removal_list replaced by ' '\n",
    "def full_remove(x, removal_list):\n",
    "    for w in removal_list:\n",
    "        x = x.replace(w, ' ')\n",
    "    return x\n",
    "\n",
    "## Remove digits，将所有数字替换成空格\n",
    "digits = [str(x) for x in range(10)]\n",
    "digit_less = [full_remove(x, digits) for x in sentences]\n",
    "\n",
    "## Remove punctuation\n",
    "punc_less = [full_remove(x, list(string.punctuation)) for x in digit_less]\n",
    "\n",
    "## Make everything lower-case\n",
    "sents_lower = [x.lower() for x in punc_less]\n",
    "\n",
    "## Define our stop words\n",
    "stop_set = set(['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from'])\n",
    "\n",
    "## Remove stop words\n",
    "sents_split = [x.split() for x in sents_lower]\n",
    "sents_processed = [\" \".join(list(filter(lambda a: a not in stop_set, x))) for x in sents_split]\n",
    "\n",
    "## Transform to bag of words representation.\n",
    "## 在转换表示的过程中，难免会有信息的损失\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 4500)\n",
    "data_features = vectorizer.fit_transform(sents_processed)\n",
    "\n",
    "## Append '1' to the end of each vector.\n",
    "data_mat = data_features.toarray()\n",
    "\n",
    "## Split the data into testing and training sets\n",
    "np.random.seed(0)\n",
    "## 最终取到的测试样本中，两种不同的评价各占50%\n",
    "test_inds = np.append(np.random.choice((np.where(y==-1))[0], 250, replace=False), np.random.choice((np.where(y==1))[0], 250, replace=False))\n",
    "train_inds = list(set(range(len(labels))) - set(test_inds))\n",
    "\n",
    "train_data = data_mat[train_inds,]\n",
    "train_labels = y[train_inds]\n",
    "\n",
    "test_data = data_mat[test_inds,]\n",
    "test_labels = y[test_inds]\n",
    "\n",
    "print(\"train data: \", train_data.shape)\n",
    "print(\"test data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitting a support vector machine to the data\n",
    "\n",
    "In support vector machines, we are given a set of examples $(x_1, y_1), \\ldots, (x_n, y_n)$ and we want to find a weight vector $w \\in \\mathbb{R}^d$ that solves the following optimization problem:\n",
    "\n",
    "$$ \\min_{w \\in \\mathbb{R}^d} \\| w \\|^2 + C \\sum_{i=1}^n \\xi_i $$\n",
    "$$ \\text{subject to } y_i \\langle w, x_i \\rangle \\geq 1 - \\xi_i \\text{ for all } i=1,\\ldots, n$$\n",
    "\n",
    "`scikit-learn` provides an SVM solver that we will use. The following routine takes as input the constant `C` (from the above optimization problem) and returns the training and test error of the resulting SVM model. It is invoked as follows:\n",
    "\n",
    "* `training_error, test_error = fit_classifier(C)`\n",
    "\n",
    "The default value for parameter `C` is 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    3,    5, ..., 2997, 2998, 2999], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.where(y==-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def fit_classifier(C_value=1.0):\n",
    "    clf = svm.LinearSVC(C=C_value, loss='hinge')\n",
    "    clf.fit(train_data,train_labels)\n",
    "    ## Get predictions on training data\n",
    "    train_preds = clf.predict(train_data)  # 在training的过程中，不需要设置终止条件，在此时取到最优解也不可能误差为0（过拟合并不是一定会出现）\n",
    "    train_error = float(np.sum((train_preds > 0.0) != (train_labels > 0.0)))/len(train_labels)  # 分类错误的比例\n",
    "    ## Get predictions on test data\n",
    "    test_preds = clf.predict(test_data)\n",
    "    test_error = float(np.sum((test_preds > 0.0) != (test_labels > 0.0)))/len(test_labels)\n",
    "    ##\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 0.01: train 0.216 test 0.250\n",
      "Error rate for C = 0.10: train 0.074 test 0.174\n",
      "Error rate for C = 1.00: train 0.011 test 0.152\n",
      "Error rate for C = 10.00: train 0.002 test 0.188\n",
      "Error rate for C = 100.00: train 0.002 test 0.196\n",
      "Error rate for C = 1000.00: train 0.004 test 0.214\n",
      "Error rate for C = 10000.00: train 0.001 test 0.208\n"
     ]
    }
   ],
   "source": [
    "cvals = [0.01,0.1,1.0,10.0,100.0,1000.0,10000.0]  # 选择超参数，这里的test set相当于验证集\n",
    "for c in cvals:\n",
    "    train_error, test_error = fit_classifier(c)\n",
    "    print (\"Error rate for C = %0.2f: train %0.3f test %0.3f\" % (c, train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluating C by k-fold cross-validation\n",
    "\n",
    "As we can see, the choice of `C` has a very significant effect on the performance of the SVM classifier. We were able to assess this because we have a separate test set. In general, however, this is a luxury we won't possess. How can we choose `C` based only on the training set?\n",
    "\n",
    "A reasonable way to estimate the error associated with a specific value of `C` is by **`k-fold cross validation`**:\n",
    "* Partition the training set `S` into `k` equal-sized sized subsets `S_1, S_2, ..., S_k`.\n",
    "* For `i=1,2,...,k`, train a classifier with parameter `C` on `S - S_i` (all the training data except `S_i`) and test it on `S_i` to get error estimate `e_i`.\n",
    "* Average the errors: `(e_1 + ... + e_k)/k`\n",
    "\n",
    "The following procedure, **cross_validation_error**, does exactly this. It takes as input:\n",
    "* the training set `x,y`\n",
    "* the value of `C` to be evaluated\n",
    "* the integer `k`\n",
    "\n",
    "and it returns the estimated error of the classifier for that particular setting of `C`. <font color=\"magenta\">Look over the code carefully to understand exactly what it is doing.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_error(x,y,C_value,k):\n",
    "    n = len(y)\n",
    "    ## Randomly shuffle indices\n",
    "    indices = np.random.permutation(n)\n",
    "    \n",
    "    ## Initialize error\n",
    "    err = 0.0\n",
    "    \n",
    "    ## Iterate over partitions\n",
    "    for i in range(k):\n",
    "        ## Partition indices\n",
    "        test_indices = indices[int(i*(n/k)):int((i+1)*(n/k) - 1)]\n",
    "        # https://docs.scipy.org/doc/numpy/reference/generated/numpy.setdiff1d.html\n",
    "        train_indices = np.setdiff1d(indices, test_indices)  # 还有这种操作！！！\n",
    "        \n",
    "        ## Train classifier with parameter c\n",
    "        clf = svm.LinearSVC(C=C_value, loss='hinge')\n",
    "        clf.fit(x[train_indices], y[train_indices])\n",
    "        \n",
    "        ## Get predictions on test partition\n",
    "        preds = clf.predict(x[test_indices])\n",
    "        \n",
    "        ## Compute error\n",
    "        err += float(np.sum((preds > 0.0) != (y[test_indices] > 0.0)))/len(test_indices)\n",
    "        \n",
    "    return err/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Picking a value of C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure **cross_validation_error** (above) evaluates a single candidate value of `C`. We need to use it repeatedly to identify a good `C`. \n",
    "\n",
    "<font color=\"magenta\">**For you to do:**</font> Write a function to choose `C`. It will be invoked as follows:\n",
    "\n",
    "* `c, err = choose_parameter(x,y,k)`\n",
    "\n",
    "where\n",
    "* `x,y` is the training data\n",
    "* `k` is the number of folds of cross-validation\n",
    "* `c` is chosen value of the parameter `C`\n",
    "* `err` is the cross-validation error estimate at `c`\n",
    "\n",
    "<font color=\"magenta\">Note:</font> This is a tricky business because a priori, even the order of magnitude of `C` is unknown. Should it be 0.0001 or 10000? You might want to think about trying multiple values that are arranged in a geometric progression (such as powers of ten). *In addition to returning a specific value of `C`, your function should **plot** the cross-validation errors for all the values of `C` it tried out (possibly using a log-scale for the `C`-axis).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-04,   1.00000000e-03,   1.00000000e-02,\n",
       "         1.00000000e-01,   1.00000000e+00,   1.00000000e+01,\n",
       "         1.00000000e+02,   1.00000000e+03,   1.00000000e+04])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.geomspace(1e-4, 1e4, 9)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4], dtype=int64),)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_err_inx = np.where(errors==np.min(errors))\n",
    "min_err_inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors==np.min(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33253012048192776,\n",
       " 0.32931726907630526,\n",
       " 0.27309236947791166,\n",
       " 0.19076305220883533,\n",
       " 0.1823293172690763,\n",
       " 0.21084337349397586,\n",
       " 0.2265060240963855,\n",
       " 0.23373493975903617,\n",
       " 0.22409638554216865]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([])\n",
    "aa = np.append(aa, [2])\n",
    "np.append(aa, [2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34016064,  0.33413655,  0.28032129,  0.19558233,  0.18995984,\n",
       "        0.22128514,  0.22208835,  0.22971888,  0.22369478,  0.32690763,\n",
       "        0.33534137,  0.28433735,  0.19598394,  0.19839357,  0.20843373,\n",
       "        0.2248996 ,  0.23694779,  0.22650602])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = np.asarray(errors)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.append(errors, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34016064,  0.33413655,  0.28032129,  0.19558233,  0.18995984,\n",
       "        0.22128514,  0.22208835,  0.22971888,  0.22369478,  0.32690763,\n",
       "        0.33534137,  0.28433735,  0.19598394,  0.19839357,  0.20843373,\n",
       "        0.2248996 ,  0.23694779,  0.22650602,  3.        ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvals2 = np.geomspace(1e-4, 1e4, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_parameter(x,y,k):\n",
    "    errs = np.array([])\n",
    "    for i in cvals2:\n",
    "        err = cross_validation_error(train_data, train_labels, i, k)\n",
    "        errs = np.append(errs, err)\n",
    "    min_err_inx = np.where(errors==np.min(errors))\n",
    "    print(errs)\n",
    "    return cvals2[min_err_inx], errors[min_err_inx], errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out your routine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34618474  0.32449799  0.28232932  0.19076305  0.18795181  0.20722892\n",
      "  0.21606426  0.22369478  0.22931727]\n",
      "Choice of C:  [ 1.]\n",
      "Cross-validation error estimate:  [ 0.18473896]\n",
      "Test error:  0.152\n"
     ]
    }
   ],
   "source": [
    "c, err, errors = choose_parameter(train_data, train_labels, 10)\n",
    "print(\"Choice of C: \", c)\n",
    "print(\"Cross-validation error estimate: \", err)\n",
    "## Train it and test it\n",
    "clf = svm.LinearSVC(C=c, loss='hinge')\n",
    "clf.fit(train_data, train_labels)\n",
    "preds = clf.predict(test_data)\n",
    "error = float(np.sum((preds > 0.0) != (test_labels > 0.0)))/len(test_labels)\n",
    "print(\"Test error: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34136546,  0.3253012 ,  0.28032129,  0.19076305,  0.18473896,\n",
       "        0.20923695,  0.22248996,  0.24297189,  0.23654618])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**For you to ponder:**</font> How does the plot of cross-validation errors for different `C` look? Is there clearly a trough in which the returned value of `C` falls? Does the plot provide some reassurance that the choice is reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-13.28771238  -9.96578428  -6.64385619  -3.32192809   0.           3.32192809\n",
      "   6.64385619   9.96578428  13.28771238]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEACAYAAABLfPrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e02be7e390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(np.log2(cvals2))\n",
    "plt.plot(np.log2(cvals2), errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "344px",
    "left": "1px",
    "right": "20px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
